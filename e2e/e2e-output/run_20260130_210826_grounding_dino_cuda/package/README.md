# e2e_grounding_dino

ROS2 vision node running **grounding_dino** (grounding_dino_base) on **cuda**.

Generated by [vision-factory](https://github.com/robocore/vision-factory).

## Quick Start

```bash
# Install Python dependencies
pip install -r requirements.txt

# Build with colcon
cd /path/to/ros_ws/src
cp -r e2e_grounding_dino .
cd ..
colcon build --packages-select e2e_grounding_dino
source install/setup.bash

# Run
ros2 launch e2e_grounding_dino vision.launch.py
```

## Docker

```bash
docker build -t e2e_grounding_dino .
docker run --gpus all --rm e2e_grounding_dino
```

## Configuration

Edit `config/params.yaml`:

```yaml
e2e_grounding_dino_node:
  ros__parameters:
    input_topic: "/camera/image_raw"
    default_prompt: "person . car . dog . cat"  # Default text prompt (phrases separated by ' . ')
    box_threshold: 0.35  # Minimum box confidence
    text_threshold: 0.25  # Minimum text-box matching confidence
```

## Topics

### Subscribed
- `input_topic` (sensor_msgs/Image) — Input camera image
- `prompt` (std_msgs/String) — Text prompt

### Published
- `detections` (DetectionArray)
- `visualization` (sensor_msgs/Image) — Image with labeled bounding boxes

## Fine-tuned Models

To use your own fine-tuned weights, update `config/params.yaml`:

```yaml
e2e_grounding_dino_node:
  ros__parameters:
    # Point to your custom weights:
    # weights_path: "/path/to/my_finetuned_model.pt"
```

The architecture code is identical — only the weights change.
