# RTMPose Model Manifest
# Real-time multi-person pose estimation

model:
  name: rtmpose
  family: mmpose
  variants:
    - rtmpose_tiny
    - rtmpose_s
    - rtmpose_m
    - rtmpose_l
    - rtmpose_x
    # Whole-body variants (body + hands + face)
    - rtmpose_wholebody_m
    - rtmpose_wholebody_l
  default_variant: rtmpose_m

source:
  type: mmpose
  repo: open-mmlab/mmpose
  config_prefix: rtmpose
  checkpoint_urls:
    rtmpose_m: https://download.openmmlab.com/mmpose/v1/projects/rtmposev1/rtmpose-m_simcc-body7_pt-body7_420e-256x192-e48f03d0_20230504.pth

input:
  type: image
  format: rgb
  preprocessing:
    # RTMPose typically runs on pre-cropped person detections
    requires_detection: true  # Needs bounding boxes from detector
    resize:
      method: resize
      target_size: [192, 256]  # width x height
    normalize:
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]
      scale: 255.0

output:
  type: keypoints
  format: coco  # 17 keypoints for body, 133 for wholebody
  fields:
    - name: keypoints
      dtype: float32
      shape: [N, K, 2]
      description: Keypoint coordinates (x, y) for N persons, K keypoints
    - name: scores
      dtype: float32
      shape: [N, K]
      description: Confidence score per keypoint
    - name: person_scores
      dtype: float32
      shape: [N]
      description: Overall person confidence

  keypoint_names:
    body17:  # COCO format
      - nose
      - left_eye
      - right_eye
      - left_ear
      - right_ear
      - left_shoulder
      - right_shoulder
      - left_elbow
      - right_elbow
      - left_wrist
      - right_wrist
      - left_hip
      - right_hip
      - left_knee
      - right_knee
      - left_ankle
      - right_ankle

  skeleton:
    - [15, 13]  # left_ankle -> left_knee
    - [13, 11]  # left_knee -> left_hip
    - [16, 14]  # right_ankle -> right_knee
    - [14, 12]  # right_knee -> right_hip
    - [11, 12]  # left_hip -> right_hip
    - [5, 11]   # left_shoulder -> left_hip
    - [6, 12]   # right_shoulder -> right_hip
    - [5, 6]    # left_shoulder -> right_shoulder
    - [5, 7]    # left_shoulder -> left_elbow
    - [6, 8]    # right_shoulder -> right_elbow
    - [7, 9]    # left_elbow -> left_wrist
    - [8, 10]   # right_elbow -> right_wrist
    - [1, 2]    # left_eye -> right_eye
    - [0, 1]    # nose -> left_eye
    - [0, 2]    # nose -> right_eye
    - [1, 3]    # left_eye -> left_ear
    - [2, 4]    # right_eye -> right_ear
    - [3, 5]    # left_ear -> left_shoulder
    - [4, 6]    # right_ear -> right_shoulder

postprocessing:
  keypoint_threshold: 0.3
  # Transform keypoints back to original image coordinates
  transform_to_original: true

ros:
  publishers:
    - topic: keypoints
      msg_type: KeypointArray
      frame_id: camera_frame
      description: Detected keypoints for all persons
    - topic: visualization
      msg_type: sensor_msgs/Image
      encoding: rgb8
      description: Image with skeleton overlay

  subscribers:
    - topic: detections
      msg_type: DetectionArray
      description: Person bounding boxes from detector

  parameters:
    - name: detector_model
      type: string
      default: yolo_v8
      description: Which detection model to use for person detection
    - name: keypoint_threshold
      type: float
      default: 0.3
      description: Minimum keypoint confidence to publish
    - name: draw_skeleton
      type: bool
      default: true
      description: Draw skeleton connections in visualization

resources:
  vram:
    rtmpose_tiny: 200
    rtmpose_s: 300
    rtmpose_m: 500
    rtmpose_l: 800
    rtmpose_x: 1200
    rtmpose_wholebody_m: 800
    rtmpose_wholebody_l: 1200
