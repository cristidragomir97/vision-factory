"""ROCm inference runner for {{ model_name }}.

ROCm uses the same PyTorch API as CUDA â€” the difference is the torch build.
"""

import time
import torch
from .model import Model


class {{ runner_class }}:
    def __init__(self, node):
        self.node = node
        self.logger = node.get_logger()
        # ROCm devices appear as 'cuda' in PyTorch
        self.device = torch.device('cuda:{{ device_id }}')

        self.logger.info(f'{{ runner_class }}: using device {self.device} (ROCm)')

        t0 = time.monotonic()
        variant = node.get_parameter('variant').value
        self.model = Model(node, variant)
        self.model.load(self.device)
        self.logger.info(f'{{ runner_class }}: model loaded in {time.monotonic() - t0:.2f}s')

{% if model_family != "ultralytics" %}
        # torch.compile: fuses ops and eliminates Python overhead after warmup.
        self._use_compile = node.declare_parameter('use_torch_compile', True).value
        if self._use_compile:
            self.logger.info('{{ runner_class }}: applying torch.compile to forward()...')
            t0 = time.monotonic()
            self.model.forward = torch.compile(self.model.forward)
            self.logger.info(f'{{ runner_class }}: torch.compile applied in {time.monotonic() - t0:.2f}s '
                             '(first inference will trigger compilation)')
        else:
            self.logger.info('{{ runner_class }}: torch.compile disabled via parameter')
{% endif %}

        self.logger.info(f'{{ runner_class }}: ready.')

{% if model_family == "ultralytics" %}
    def infer(self, image):
        raw = self.model.predict(image)
        return self.model.postprocess(raw)
{% elif has_text_input %}
    def infer(self, image, text=None):
        inputs = self.model.preprocess(image, text=text)
        with torch.no_grad():
            outputs = self.model.forward(inputs)
        return self.model.postprocess(outputs, original_size=image.shape[:2])
{% else %}
    def infer(self, image):
        inputs = self.model.preprocess(image)
        with torch.no_grad():
            outputs = self.model.forward(inputs)
        return self.model.postprocess(outputs, original_size=image.shape[:2])
{% endif %}
